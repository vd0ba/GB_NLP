{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97fade7b-f944-4cb4-bc77-270257eec907",
   "metadata": {},
   "source": [
    "## Практическое задание к уроку 9 по теме \"Языковое моделирование\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ddb8e-2a35-4234-b19e-c83499a7938b",
   "metadata": {},
   "source": [
    "*Разобраться с моделью генерации текста, собрать самим или взять датасет с вебинара и обучить генератор текстов.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70275636-cd0d-49bc-8451-5c8a3213fa7c",
   "metadata": {},
   "source": [
    "В данном задании напишу модель генерации текста аналогичную той, что была  \n",
    "на уроке. Но буду использовать pytorch, а также устраню ошибку, по которой  \n",
    "не использовался hidden_state модели при генерации текста, в результате чего  \n",
    "после предсказания первого символа модель получала на вход только один символ,  \n",
    "без контекста."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7036e715-298a-4205-b0d3-52ebb911cd0a",
   "metadata": {},
   "source": [
    "Загрузим библиотеки и датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eacc5d7-bf85-49ab-96f5-bbdb8889df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15e57e3e-ce4b-4ade-8289-48cb03e3c504",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "588c4c0b-adda-4690-9f27-61fd0a70106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../Теория/Lesson_9/evgenyi_onegin.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "731b8053-30c9-4620-92f5-0610255cb6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                                Роман в стихах\\n\\n                        Не мысля гордый свет забавить,\\n                        Вниманье дружбы возлюбя,\\n                        Хотел бы я тебе представить\\n                        Залог достойнее тебя,\\n                        Достойнее души прекрасной,\\n                        Святой исполненной мечты,\\n                        Поэзии живой и ясной,\\n                        Высо'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07066a58-7543-4716-befe-4e98cec7ec53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286984"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea4191-1e71-42cd-ab6e-75868259b74e",
   "metadata": {},
   "source": [
    "Создадим словарь символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55e77d67-618b-4ede-8768-9efcb1d00a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e346976-f5fd-4f85-96ed-8795cb2fa09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01b6af1-b2b6-4f72-b77a-3eabc1b28c12",
   "metadata": {},
   "source": [
    "Создадим словари маппинга символов и их индексов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c568c760-de03-48ba-9aad-906287d23b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {c: i for i, c in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_idx = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b9333d4-8634-4753-88c5-5f4f1d7faff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 71, 110, 104, 109, 116,  99, 112, 103, 115,   1,  87, 104, 115,\n",
       "       102, 104, 104, 101, 107, 122,   1,  85, 118, 123, 109, 107, 112,\n",
       "         0,   0,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,  76, 101, 102, 104, 112,\n",
       "       107, 108,   1,  84, 112, 104, 102, 107, 112,   0,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_idx[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d2f743c-9213-4b3c-9846-96ff741438e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286984,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0795d0-0f06-477f-b47a-2fe0b6e03796",
   "metadata": {},
   "source": [
    "Напишем класс датасета, в котором будем разбивать текст  \n",
    "на куски заданной последовательности, а также сделаем  \n",
    "смещение входной последовательности для получения таргета.  \n",
    "То есть предсказывать будем следующий символ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a2719c8-4c9e-409f-b5be-d1b9a03f86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text_idx, seq_length=100):\n",
    "        \n",
    "        remainder = len(text_idx) % seq_length\n",
    "        self.text = text_idx[:-remainder]\n",
    "        self.text = self.text.reshape(-1, seq_length)\n",
    "        self.text = torch.from_numpy(self.text)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.text[index][:-1], self.text[index][1:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0ac16-cd8c-4780-882f-eeaf6777720f",
   "metadata": {},
   "source": [
    "Создадим даталоадер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6570bba-3cd2-4c67-9e9d-7f7577c01e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "SEQ_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20958a6e-1a0b-4266-971e-d601f5e63317",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(RANDOM_STATE)\n",
    "\n",
    "dataset = TextDataset(text_idx, SEQ_LENGTH)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                     batch_size=BATCH_SIZE,\n",
    "                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa26930f-49ce-4792-bae4-3c4db4359488",
   "metadata": {},
   "source": [
    "Напишем сеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e188f1f-893e-4587-bebc-eb249fd3d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, embed_dim=128, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, embed_dim)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, VOCAB_SIZE)\n",
    "        \n",
    "    def forward(self, x, h_0=None):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Вектор скрытого состояния будем использовать при генерации\n",
    "        # текста, сохранять его, чтобы при предсказании символов не  \n",
    "        # нужно было каждый раз прогонять всю последовательность\n",
    "        x, h_n = self.gru(x, h_0) \n",
    "        \n",
    "        # Полносвязный слой получает последовательность и для каждого  \n",
    "        # её элемента выдаёт последовательность логитов\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x.permute(0, 2, 1), h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eb46ba2-2acd-4e11-aa0d-c4d2d4184023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Net                                      --\n",
       "├─Embedding: 1-1                         33,536\n",
       "├─GRU: 1-2                               2,758,656\n",
       "├─Linear: 1-3                            67,203\n",
       "=================================================================\n",
       "Total params: 2,859,395\n",
       "Trainable params: 2,859,395\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(Net(embed_dim=256, hidden_dim=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dad477-de61-40f6-8184-44bc7b94aab5",
   "metadata": {},
   "source": [
    "На гиперпараметрах, на которых будем обучать сеть, имеем чуть  \n",
    "меньше 3 млн. параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e2292c8-973e-4662-94d8-d737ccaeb6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe0011-b32e-4729-aa6a-cd623aaf205c",
   "metadata": {},
   "source": [
    "Напишем функцию для обучения сети. Здесь всё стандартно,  \n",
    "кроме того, что у нас нет валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5d843e3-ac77-4cd2-be1a-ccc6b0f1fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(epochs=5, embed_dim=128, hidden_dim=256, lr=1e-3, return_net=False):\n",
    "    \n",
    "    torch.random.manual_seed(RANDOM_STATE)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    net = Net(embed_dim=embed_dim, hidden_dim=hidden_dim).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        losses = np.array([])\n",
    "\n",
    "        for inputs, labels in loader:\n",
    "            net.train()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)[0]\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses = np.append(losses, loss.item())\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
    "              f'Loss: {losses.mean():.3f}. ')\n",
    "\n",
    "    print('Training is finished!')\n",
    "    if return_net:\n",
    "        return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9689b1f-9abd-4bdf-82e3-279fb5e53c53",
   "metadata": {},
   "source": [
    "Обучим сеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bc94ada-eb7f-403a-a003-e55fe4067677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]. Loss: 1.915. \n",
      "Epoch [2/50]. Loss: 1.358. \n",
      "Epoch [3/50]. Loss: 1.229. \n",
      "Epoch [4/50]. Loss: 1.156. \n",
      "Epoch [5/50]. Loss: 1.104. \n",
      "Epoch [6/50]. Loss: 1.056. \n",
      "Epoch [7/50]. Loss: 1.009. \n",
      "Epoch [8/50]. Loss: 0.982. \n",
      "Epoch [9/50]. Loss: 0.933. \n",
      "Epoch [10/50]. Loss: 0.916. \n",
      "Epoch [11/50]. Loss: 0.881. \n",
      "Epoch [12/50]. Loss: 0.848. \n",
      "Epoch [13/50]. Loss: 0.813. \n",
      "Epoch [14/50]. Loss: 0.815. \n",
      "Epoch [15/50]. Loss: 0.773. \n",
      "Epoch [16/50]. Loss: 0.736. \n",
      "Epoch [17/50]. Loss: 0.697. \n",
      "Epoch [18/50]. Loss: 0.660. \n",
      "Epoch [19/50]. Loss: 0.627. \n",
      "Epoch [20/50]. Loss: 0.601. \n",
      "Epoch [21/50]. Loss: 0.565. \n",
      "Epoch [22/50]. Loss: 0.533. \n",
      "Epoch [23/50]. Loss: 0.510. \n",
      "Epoch [24/50]. Loss: 0.473. \n",
      "Epoch [25/50]. Loss: 0.449. \n",
      "Epoch [26/50]. Loss: 0.412. \n",
      "Epoch [27/50]. Loss: 0.388. \n",
      "Epoch [28/50]. Loss: 0.381. \n",
      "Epoch [29/50]. Loss: 0.349. \n",
      "Epoch [30/50]. Loss: 0.322. \n",
      "Epoch [31/50]. Loss: 0.302. \n",
      "Epoch [32/50]. Loss: 0.286. \n",
      "Epoch [33/50]. Loss: 0.275. \n",
      "Epoch [34/50]. Loss: 0.262. \n",
      "Epoch [35/50]. Loss: 0.244. \n",
      "Epoch [36/50]. Loss: 0.247. \n",
      "Epoch [37/50]. Loss: 0.228. \n",
      "Epoch [38/50]. Loss: 0.226. \n",
      "Epoch [39/50]. Loss: 0.219. \n",
      "Epoch [40/50]. Loss: 0.212. \n",
      "Epoch [41/50]. Loss: 0.199. \n",
      "Epoch [42/50]. Loss: 0.204. \n",
      "Epoch [43/50]. Loss: 0.197. \n",
      "Epoch [44/50]. Loss: 0.196. \n",
      "Epoch [45/50]. Loss: 0.182. \n",
      "Epoch [46/50]. Loss: 0.190. \n",
      "Epoch [47/50]. Loss: 0.193. \n",
      "Epoch [48/50]. Loss: 0.171. \n",
      "Epoch [49/50]. Loss: 0.176. \n",
      "Epoch [50/50]. Loss: 0.218. \n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "net = train_nn(epochs=50, embed_dim=256, hidden_dim=512, return_net=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8970cef0-2ca4-4f29-91ae-8310986cbb41",
   "metadata": {},
   "source": [
    "Напишем функцию для генерации текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "babc501f-404e-4f92-b3c1-73d268c4ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, generated_length=100, temperature=1., randomized=False):\n",
    "    \n",
    "    '''\n",
    "    start_string - начальные символы строки, которую нужно сгенерировать\n",
    "    \n",
    "    generated_length - количество символов, которые будем генерировать\n",
    "    \n",
    "    temperature - температура, некоторая степень хаоса, влияющая на то,\n",
    "    как сильно будут влиять распределения логитов на выходе сети на выбор\n",
    "    соответствующих символов при предсказании. Чем больше значение, тем  \n",
    "    меньше влияние логитов и тем случайнее предсказание\n",
    "    \n",
    "    randomized - генерировать ли каждый раз новую последовательность\n",
    "    '''\n",
    "    \n",
    "    if not randomized:\n",
    "        torch.random.manual_seed(RANDOM_STATE)\n",
    "    \n",
    "    # Переводим последовательность в индексы\n",
    "    idx_string = torch.IntTensor([char2idx[c] for c in start_string]).to(device)\n",
    "    \n",
    "    # Вектор скрытого состояния для слоя RNN. Инициализируем \"наном\", что  \n",
    "    # равносильно нулевому вектору\n",
    "    hidden_state = None \n",
    "    \n",
    "    for _ in range(generated_length):\n",
    "        \n",
    "        # На первой итерации пропускаем всю начальную последовательность через модель, \n",
    "        # на входе имеем нулевой вектор скрытого состояния. На последующих итерациях пропускаем\n",
    "        # только последний предсказанный символ, а также накопленную информацию о контексте  \n",
    "        # в векторе скрытого состояния\n",
    "        predicted_idx, hidden_state = model(idx_string[None, :], hidden_state)\n",
    "        \n",
    "        # Берём последний символ в единственном батче. Получаем его логиты,  \n",
    "        # где каждый символ словаря имеет определённый скор (score)\n",
    "        predicted_idx = predicted_idx[0, :, -1]\n",
    "        \n",
    "        # Вводим в действие температуру\n",
    "        predicted_idx /= temperature\n",
    "        \n",
    "        # Берём кандидата из распределения логитов\n",
    "        predicted_idx = torch.distributions.categorical.logits_to_probs(predicted_idx) \n",
    "        predicted_idx = torch.multinomial(predicted_idx, num_samples=1)\n",
    "        \n",
    "        # В следующей итерации на вход сети подаём предсказанный символ\n",
    "        idx_string = predicted_idx\n",
    "        \n",
    "        # Расшифровываем кандидата через словарь маппинга\n",
    "        predicted_char = idx2char[predicted_idx]\n",
    "        \n",
    "        # Добавляем предсказание к строке\n",
    "        start_string += predicted_char\n",
    "        \n",
    "    return start_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5435b5-6992-4832-981c-915a93b13dc6",
   "metadata": {},
   "source": [
    "Посмотрим на предсказание модели. На вход подадим строку из  \n",
    "стихотворения М.Ю. Лермонтова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e19d99-19c8-4479-8809-31d765710d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Белеет парус одинокий голос летит,\n",
      "                               И славы селенить бы всеми\n",
      "                         Замену туский один печальных:\n",
      "                        За ним сердцем и умом крест.\n",
      "\n",
      "                                                          XLV\n",
      "\n",
      "                        Того, почта задержало спясь!\n",
      "                        Когда б мне быть отцом, супругом\n",
      "                        Обманчир, когда ночная тень,\n",
      "                        Приемы скоро приняла!\n",
      "                        Услышу ль вновь поражен.\n",
      "\n",
      "                                          XLIII\n",
      "\n",
      "                          Онегин вышел иногда:\n",
      "                         Всем сердцем юноша лежит,\n",
      "                         И все дела, все речи мерит\n",
      "                         И намара не читал он.\n",
      "\n",
      "                                   XXXIV\n",
      "\n",
      "                         Пред ним на стол разговор странность\n",
      "                        И нам досталось она\n",
      "                        Он должен быть, без гремене;\n",
      "                        В глуши забытого селенья\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "text = 'Белеет парус одинокий '\n",
    "print(generate_text(net, text, generated_length=1000, temperature=0.5, randomized=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7573c-2531-4bd3-81b3-23fd1e5999dd",
   "metadata": {},
   "source": [
    "В целом с задачей справились, но хочется ещё \"покрутить\" параметр температуры.  \n",
    "Что если зададим достаточно большое значение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ff12a1e-793d-42d6-807a-a0c9ec8b3f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Белеет парус одинокий фои),\n",
      "               ЛебаньегНа ДлягАзиБйи Рофйой,\n",
      "      К       Неgел сГhам Pan.otеbнью,\n",
      "                Влешеи тесныймА, (Брет дрcвнукЛ\n",
      "                    ftpilnТ Cs иL РiotчуА ЦилыщихХты-Ппит\"\n",
      "                 Я утременУА l25вы\n",
      "                   ЧЗароИ зwвю берегgа\n",
      " Д            Mдnеe!ф -\n",
      "             К грАди, Лще та прiмал, живъей;\n",
      "     \"    Знячным похв'-vdGoбрeш;\n",
      "    Бu               Небо был, сквозь вернойut\n",
      "              Дырено тгнимуX\n",
      " ,            тяпижуО чтюФт.\n",
      "             Х zrа,щийЖки Цицеримых\n",
      "              N плючки дизто0оeДрагии\n",
      "            А плАмШpУ Татицы t7ва4,\n",
      "                - Бариты СЮиn} живык.\n",
      "              ХовЬаяческийФяГ\n",
      "И           Н е тежкаЦи,БЖь Форны,\n",
      "                   Улча, пламеRнщю цЖвальных щh2еt\n",
      "         Бы Смлогих дводил.\n",
      "     .         Вщает бж! бuсВрадцейный Юльзыq}\n",
      "              И зналдях флата; Журант.\n",
      "  \"               Пьюм ийБегПе ейжила:\n",
      "                 СъягСенул - чест вет?Ча-Хо;\n",
      "             с асce, ШриВка-Бурш!), --Race Msmeos.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(net, text, generated_length=1000, temperature=3., randomized=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed8f878-bb5c-4e2c-8292-d54d8bc80d00",
   "metadata": {},
   "source": [
    "Получили хаос, как и должно было быть, ведь теперь величина логитов всех  \n",
    "символов становится очень близкой. Теперь попробуем малое значение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbbd9934-845a-4759-afaf-98c558b14cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Белеет парус одинокий голос лир,\n",
      "                         Не привлекла б она очей.\n",
      "                         Да стол подвинь; я скоро лягкой,\n",
      "                         Предчувствия теснили грудь.\n",
      "                        Простите, игры золотые!\n",
      "                        Он так привык перевестила;\n",
      "                        Стихи введут в употреблен;\n",
      "                        Конечно, не один Евгений\n",
      "                        На прелестных помительной -\n",
      "                        Волшебный дев умел судит\n",
      "                         Себе присвоить ум чужой;\n",
      "                        От жад, покорны старинной\n",
      "                        Они не страдали нравими\n",
      "                            Меняю милых полковая!\n",
      "                         Да стол подвинь; я скоро лягу;\n",
      "                        И там уж ты не был того: для всех,\n",
      "                                                                                                                                                                                                                       \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(net, text, generated_length=1000, temperature=0.0001, randomized=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d984e-f3a7-4ba4-9d40-5daabbbc603e",
   "metadata": {},
   "source": [
    "Интересный факт здесь в том, что теперь влияние сэмплирования по логитам сведено  \n",
    "к минимуму. Почти всегда будут выбираться кандидаты с самой высокой вероятностью,  \n",
    "и гиперпараметр randomized теряет своё действие:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "011a497e-32b5-446d-b197-dc1acb77cd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(net, text, generated_length=1000, temperature=0.0001, randomized=False) == \\\n",
    "generate_text(net, text, generated_length=1000, temperature=0.0001, randomized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ae7262-7f11-42bc-b9f5-93defbabb0e1",
   "metadata": {},
   "source": [
    "Для сравнения, при \"нормальном\" значении температуры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c872de75-a59a-48ad-9bbd-8edadc375929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(net, text, generated_length=1000, temperature=0.5, randomized=False) == \\\n",
    "generate_text(net, text, generated_length=1000, temperature=0.5, randomized=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
