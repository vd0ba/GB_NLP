{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045fd6a2-7f59-4be2-8e8d-63d9c33e2a17",
   "metadata": {},
   "source": [
    "## Практическое задание к уроку 8 по теме \"Рекуррентные нейронные сети RNN LSTM GRU\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd22248f-166d-403d-87d4-59e14eab43ac",
   "metadata": {},
   "source": [
    "Выяснить, какая архитектура больше подходит для задачи сентимент анализа на данных с вебинара  \n",
    "1. построить свёрточную архитектуру  \n",
    "2. построить различные архитектуры с RNN  \n",
    "3. построить совместные архитектуры CNN -> RNN и/или (RNN -> CNN)  \n",
    "4. сделать выводы что получилось лучше  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9db0ee-bce9-4d08-bfcc-37eabcb480ee",
   "metadata": {},
   "source": [
    "Загрузим библиотеки и датасеты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2246ab5-79c5-4537-883b-2c71c86bc9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import cpu_count, Pool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from string import punctuation\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "import urlextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f14ec13e-a91c-4394-a504-bdb623522b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee0059a-3b34-4460-a76b-2ca8c0de5463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((181467, 2), (22683, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train.csv', index_col='id')\n",
    "df_val = pd.read_csv('data/val.csv', index_col='id')\n",
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b5fb0f-65cf-4c83-a19c-0f5fe35b0de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  class\n",
       "id                                                          \n",
       "0   @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4635d249-cb9a-4f0e-8838-10a91dc1c82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 181467 entries, 0 to 181466\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    181467 non-null  object\n",
      " 1   class   181467 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec41c7eb-b751-4d6f-b395-583348fa516d",
   "metadata": {},
   "source": [
    "Пропущенных значений нет, посмотрим на распределение классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6745151-eef8-4bb0-8226-0eb660277f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    92063\n",
       "0    89404\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af59d6e-358b-477a-99d3-152191f80ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11449\n",
       "0    11234\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baafbe07-7246-4f60-a437-2b494659b662",
   "metadata": {},
   "source": [
    "В этот раз классы распределены почти поровну, будем использовать метрику accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d107246-ebf5-49fe-93bc-851ea6490b0a",
   "metadata": {},
   "source": [
    "Для начала обучим бейзлайн. В качестве бейзлайна возьмём модель логистической регрессии с предварительной векторизацией  \n",
    "с помощью TfidfVectorizer. Обучим две таких модели: сначала будем делать токенизацию по словам, а потом по символам.  \n",
    "Посмотрим, какой вариант будет лучше, так и будем дальше обрабатывать текст. Перед посимвольной токенизацией будем  \n",
    "чистить датасет от пунктуации, так как этот датасет имеет лик: учитывание скобок (смайликов) даёт даже простой модели  \n",
    "точность 99%. При такой точности сравнивать разные модели нет смысла, поэтому данный лик убираем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36d368ca-5a4b-4839-b3d4-1b5aee1e33b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "classifier = LogisticRegression(solver='sag', random_state=RANDOM_STATE)\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "baseline = make_pipeline(vectorizer, scaler, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ced9e23d-c288-4dbc-880b-e623d4f472d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.fit(df_train['text'], df_train['class']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0264e6e6-8fb4-42cf-bf79-5bdc47c454cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.781025437552352"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = baseline.predict(df_val['text'])\n",
    "accuracy_score(df_val['class'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33d49034-823f-4309-91c6-6f8c27d91c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shkin/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7878587488427456"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 5), analyzer='char', preprocessor=lambda x: re.sub(f'[{punctuation}]', ' ', x))\n",
    "baseline = make_pipeline(vectorizer, scaler, classifier)\n",
    "\n",
    "baseline.fit(df_train['text'], df_train['class'])\n",
    "pred = baseline.predict(df_val['text'])\n",
    "accuracy_score(df_val['class'], pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb278fe-cf93-43d8-9123-5e28bb89453e",
   "metadata": {},
   "source": [
    "Модель с посимвольной токенизацией оказалась лучше, поэтому далее будем токенизировать символы. Также это более интересно,\n",
    "так как ранее токенизацию делал только по словам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9ab5132-e91b-474d-a5b6-fb6fe6547b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_extractor = urlextract.URLExtract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8b6f4ae-6f10-453c-99ad-c4fd6d227e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    # Заменяем ссылки на тэг\n",
    "    urls = url_extractor.find_urls(text, only_unique=True)\n",
    "    for url in urls:\n",
    "        text = text.replace(url, ' url ')\n",
    "    \n",
    "    # Убираем характерные для твиттера обращения с никами пользователей,  \n",
    "    # не хотим, чтобы модели переобучались на чьи-то ники\n",
    "    text = re.sub('@\\w+', '', text)\n",
    "    \n",
    "    # Убираем символы переноса строки\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    \n",
    "    # Убираем пунктуацию, приводим к нижнему регистру\n",
    "    text = re.sub(f'[{punctuation}]', '', text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Делаем посимвольную токенизацию\n",
    "    text = list(text)\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a53bb3b-ac9e-481c-8970-6b8ea32cb3a1",
   "metadata": {},
   "source": [
    "Обрабатываем текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f9f3667-aff1-46d0-a9a8-3fdbc67f6afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 181467/181467 [00:11<00:00, 15653.26it/s]\n",
      "100%|██████████████████████████████████| 22683/22683 [00:01<00:00, 15718.10it/s]\n"
     ]
    }
   ],
   "source": [
    "with Pool(cpu_count()) as p:\n",
    "    df_train['processed'] = tqdm(p.imap(preprocess_text, df_train['text']), total=len(df_train))\n",
    "    df_val['processed'] = tqdm(p.imap(preprocess_text, df_val['text']), total=len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8653b54e-2194-4625-9298-a4104d2a1c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "89543       з а б и т ь   р у к а в   и   п о с т а в и ...\n",
       "84243     л е р а п о д т я г и в а й   х и м и ю   в о ...\n",
       "105255    м е н я   с е г о д н я   ж е с т о к о   р а ...\n",
       "36974       н е   н о р м а л ь н ы й   з а к а з     к ...\n",
       "97048     к а к о й т о   щ е д р ы й   п а р е н ь   в ...\n",
       "83620     у   а н д р э   т р у х а н ы   в   п е р д а ...\n",
       "56130       п о н к р а ш а   з а р е т в и т е л   с   ...\n",
       "35645     н е   н у   т о л ь к о   я   т а к   м о г л ...\n",
       "126905      д о б р о й   п я т н и ц ы   в с е м   ч и ...\n",
       "12141       у ф ф ф   м а с т е р   ч т о   н а д о   о ...\n",
       "Name: processed, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['processed'].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb601c4-d7b1-4859-b228-a2aaea6d5504",
   "metadata": {},
   "source": [
    "Для определения фиксированной длины последовательности посмотрим на распределение длин:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d262ffa-d72d-4a29-8c50-fa72e8af0af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(df_train['processed'].apply(lambda x: len(x.split(' '))), bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c8eff0-0c75-4ac8-a7b4-a5fd70840e8e",
   "metadata": {},
   "source": [
    "Примем длину последовательности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed42acf6-eb43-494a-ae0f-f31edfdadf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 170"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d689d9-6d25-4301-bd52-e66f64b58f3d",
   "metadata": {},
   "source": [
    "Создадим словарь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c88bf09-afa9-4b86-9391-c7cddd69368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ' '.join(df_train['processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43ae00b3-98ae-4beb-b8ff-dfcf9fad0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = Counter(corpus.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "318ddc90-aaf3-41f0-813c-340de91ca7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {w: i for i, w in dict(enumerate(dist.keys(), 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f62f82b-b926-4050-8755-9f51c08ed990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c022a6-a726-402d-bd6d-8131b5c14501",
   "metadata": {},
   "source": [
    "Небольшая длина словаря, так как токенизировали символы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75afbfe3-8e78-42bf-ab93-107bc66a970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocabulary) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc9e409-eb69-41f1-b65c-23e1196c995a",
   "metadata": {},
   "source": [
    "Обработаем все последовательности для соответствия фиксированной длине. Обрежем или добавим паддинг, где нужно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c14fc02-5dda-4317-aad8-7275ec6a800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_seq(text):\n",
    "    seq = []\n",
    "    for token in text.split(' '):\n",
    "        if token in vocabulary:\n",
    "            seq.append(vocabulary[token])\n",
    "    padding = [0] * (MAX_LEN - len(seq))\n",
    "    return seq[:MAX_LEN] + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1505f5b7-22ea-471d-8ecd-0b27e9029ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([text_to_seq(text) for text in df_train['processed']])\n",
    "X_val = np.array([text_to_seq(text) for text in df_val['processed']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "698fcfa0-5682-4ac9-857e-b16dd8f01326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  2, ...,  0,  0,  0],\n",
       "       [18, 19,  1, ...,  0,  0,  0],\n",
       "       [18, 19,  1, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 1,  1, 11, ...,  0,  0,  0],\n",
       "       [ 1,  1,  4, ...,  0,  0,  0],\n",
       "       [ 1,  1, 10, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf29aee-4a8b-4bf5-a172-abb24af6714d",
   "metadata": {},
   "source": [
    "Напишем класс датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a16a61c-8812-49ee-97dd-e2620be85402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataWrapper(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = torch.from_numpy(data)\n",
    "        self.target = torch.from_numpy(target)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "            \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8077120a-bd92-4bc3-9c88-99ced2bfec53",
   "metadata": {},
   "source": [
    "Обернём датасеты в даталоадеры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20b0fee0-addf-485b-bb42-6d66959db2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd12144e-c659-4200-b68a-7ea7e63d4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(RANDOM_STATE)\n",
    "\n",
    "train_dataset = DataWrapper(X_train, df_train['class'].values)\n",
    "val_dataset = DataWrapper(X_val, df_val['class'].values)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93dcee8b-7e3a-455d-8136-4bf62d0573c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d1ca1-daea-416b-9b18-0e1b7de5f068",
   "metadata": {},
   "source": [
    "Будем обучать 4 варианта сетей: свёрточную, рекуррентную, свёрточную + рекуррентную, а также рекуррентную + свёрточную.  \n",
    "Архитектура сетей, за исключением указанных выше различий, максимально приближена друг к другу, чтобы исключить влияние  \n",
    "других факторов на результат.  То есть размерность эмбеддингов, количество фильтров свёрточной сети, а также размерность вектора скрытого состояния рекуррентной сети везде были одинаковы, как и количество нейронов полносвязной части сетей. Коэффициент обучения и количество эпох подбирались индивидуально из-за различий архитектур: не хотелось, чтобы сеть показала плохой результат только из-за неправильно выставленных гиперпараметров. Количество эпох настраивалось  \n",
    "с шагом 5, а коэффициент обучения - с шагом 0,005. Перед нами не ставилась задача показать хорошую точность моделей, и,  \n",
    "забегая вперёд, только одна сеть смогла обойти бейзлайн. Задачей было сравнить эти архитектуры. Чтобы показать хороший результат, нужно усложнить модели, возможно, добавить слоёв. Например, сделать для свёрточной части сетей несколько различных свёрток (с kernel_size 2, 3, 4 и т.д.) и застекать их. Для рекуррентных сетей попробовать варианты двухслойной сети или двунаправленной сети. Это всё будет дольше обучаться, а у нас 4 модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4771409b-e860-4a8a-a738-ff1f8a77428c",
   "metadata": {},
   "source": [
    "### 1. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0dac778-53bc-41dc-b225-b63a3d303791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, embed_dim=128, conv_filters=128, kernel_size=3, conv_stride=1):\n",
    "        torch.random.manual_seed(RANDOM_STATE)\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, embed_dim, padding_idx=0)\n",
    "        \n",
    "        self.conv = nn.Sequential(nn.Conv1d(embed_dim, conv_filters, kernel_size=kernel_size, stride=conv_stride),\n",
    "                                  nn.MaxPool1d(MAX_LEN // conv_stride - kernel_size + 1),\n",
    "                                  nn.ReLU())\n",
    "        \n",
    "        self.fc1 = nn.Sequential(nn.Linear(conv_filters, conv_filters // 2),\n",
    "                                 nn.ReLU())\n",
    "        \n",
    "        self.dp02 = nn.Dropout(0.2)\n",
    "        self.dp05 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(conv_filters // 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dp02(x)\n",
    "        x = x.permute(0, 2 ,1)\n",
    "        x = torch.squeeze(self.conv(x))\n",
    "        x = self.fc1(x)\n",
    "        x = self.dp05(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b057d4d-e659-4c73-8c85-210a89e7f1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ConvNet                                  --\n",
       "├─Embedding: 1-1                         40,704\n",
       "├─Sequential: 1-2                        --\n",
       "│    └─Conv1d: 2-1                       49,280\n",
       "│    └─MaxPool1d: 2-2                    --\n",
       "│    └─ReLU: 2-3                         --\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Linear: 2-4                       8,256\n",
       "│    └─ReLU: 2-5                         --\n",
       "├─Dropout: 1-4                           --\n",
       "├─Dropout: 1-5                           --\n",
       "├─Linear: 1-6                            65\n",
       "=================================================================\n",
       "Total params: 98,305\n",
       "Trainable params: 98,305\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(ConvNet())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052709cc-3cf6-4f12-b155-3753c5860bca",
   "metadata": {},
   "source": [
    "Напишем функцию для обучения сетей, одну для всех:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72d7cc44-dec3-4425-8fcc-a1f5d36584de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(net, epochs=5, lr=1e-3):\n",
    "    \n",
    "    torch.random.manual_seed(RANDOM_STATE)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = np.array([])\n",
    "        test_losses = np.array([])\n",
    "        train_metrics = np.array([])\n",
    "        test_metrics = np.array([])\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            net.train()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses = np.append(train_losses, loss.item())\n",
    "\n",
    "            net.eval()\n",
    "            outputs = net(inputs)\n",
    "            train_metrics = np.append(train_metrics, accuracy_score(labels.cpu(), torch.squeeze(outputs > 0.5).cpu()))\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
    "              f'Train Loss: {train_losses.mean():.3f}. ' \\\n",
    "              f'Train Accuracy: {train_metrics.mean():.3f}', end='. ')\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, labels) in enumerate(val_loader):\n",
    "\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = net(inputs)\n",
    "\n",
    "                loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "                test_losses = np.append(test_losses, loss.item())\n",
    "                test_metrics = np.append(test_metrics, accuracy_score(labels.cpu(), torch.squeeze(outputs > 0.5).cpu()))\n",
    "                \n",
    "        print(f'Test loss: {test_losses.mean():.3f}. Test Accuracy: {test_metrics.mean():.3f}')\n",
    "\n",
    "    print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ce988-4d36-4d4b-aed4-fce33f553630",
   "metadata": {},
   "source": [
    "Обучим сеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17bd065e-4b05-44c5-a325-47e9563b5637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40]. Train Loss: 0.581. Train Accuracy: 0.698. Test loss: 0.535. Test Accuracy: 0.717\n",
      "Epoch [2/40]. Train Loss: 0.535. Train Accuracy: 0.736. Test loss: 0.519. Test Accuracy: 0.724\n",
      "Epoch [3/40]. Train Loss: 0.519. Train Accuracy: 0.746. Test loss: 0.509. Test Accuracy: 0.735\n",
      "Epoch [4/40]. Train Loss: 0.508. Train Accuracy: 0.755. Test loss: 0.500. Test Accuracy: 0.747\n",
      "Epoch [5/40]. Train Loss: 0.501. Train Accuracy: 0.761. Test loss: 0.496. Test Accuracy: 0.751\n",
      "Epoch [6/40]. Train Loss: 0.494. Train Accuracy: 0.766. Test loss: 0.491. Test Accuracy: 0.753\n",
      "Epoch [7/40]. Train Loss: 0.488. Train Accuracy: 0.770. Test loss: 0.489. Test Accuracy: 0.755\n",
      "Epoch [8/40]. Train Loss: 0.485. Train Accuracy: 0.772. Test loss: 0.488. Test Accuracy: 0.755\n",
      "Epoch [9/40]. Train Loss: 0.480. Train Accuracy: 0.776. Test loss: 0.486. Test Accuracy: 0.753\n",
      "Epoch [10/40]. Train Loss: 0.476. Train Accuracy: 0.779. Test loss: 0.484. Test Accuracy: 0.757\n",
      "Epoch [11/40]. Train Loss: 0.473. Train Accuracy: 0.781. Test loss: 0.487. Test Accuracy: 0.758\n",
      "Epoch [12/40]. Train Loss: 0.471. Train Accuracy: 0.783. Test loss: 0.484. Test Accuracy: 0.759\n",
      "Epoch [13/40]. Train Loss: 0.466. Train Accuracy: 0.785. Test loss: 0.497. Test Accuracy: 0.748\n",
      "Epoch [14/40]. Train Loss: 0.466. Train Accuracy: 0.786. Test loss: 0.486. Test Accuracy: 0.759\n",
      "Epoch [15/40]. Train Loss: 0.463. Train Accuracy: 0.787. Test loss: 0.512. Test Accuracy: 0.750\n",
      "Epoch [16/40]. Train Loss: 0.462. Train Accuracy: 0.789. Test loss: 0.487. Test Accuracy: 0.759\n",
      "Epoch [17/40]. Train Loss: 0.460. Train Accuracy: 0.789. Test loss: 0.480. Test Accuracy: 0.762\n",
      "Epoch [18/40]. Train Loss: 0.457. Train Accuracy: 0.792. Test loss: 0.483. Test Accuracy: 0.763\n",
      "Epoch [19/40]. Train Loss: 0.455. Train Accuracy: 0.793. Test loss: 0.482. Test Accuracy: 0.763\n",
      "Epoch [20/40]. Train Loss: 0.454. Train Accuracy: 0.795. Test loss: 0.483. Test Accuracy: 0.754\n",
      "Epoch [21/40]. Train Loss: 0.454. Train Accuracy: 0.795. Test loss: 0.481. Test Accuracy: 0.765\n",
      "Epoch [22/40]. Train Loss: 0.451. Train Accuracy: 0.796. Test loss: 0.496. Test Accuracy: 0.756\n",
      "Epoch [23/40]. Train Loss: 0.451. Train Accuracy: 0.797. Test loss: 0.479. Test Accuracy: 0.765\n",
      "Epoch [24/40]. Train Loss: 0.449. Train Accuracy: 0.800. Test loss: 0.479. Test Accuracy: 0.766\n",
      "Epoch [25/40]. Train Loss: 0.449. Train Accuracy: 0.799. Test loss: 0.480. Test Accuracy: 0.765\n",
      "Epoch [26/40]. Train Loss: 0.446. Train Accuracy: 0.799. Test loss: 0.486. Test Accuracy: 0.765\n",
      "Epoch [27/40]. Train Loss: 0.446. Train Accuracy: 0.800. Test loss: 0.480. Test Accuracy: 0.762\n",
      "Epoch [28/40]. Train Loss: 0.444. Train Accuracy: 0.801. Test loss: 0.482. Test Accuracy: 0.766\n",
      "Epoch [29/40]. Train Loss: 0.443. Train Accuracy: 0.803. Test loss: 0.483. Test Accuracy: 0.766\n",
      "Epoch [30/40]. Train Loss: 0.443. Train Accuracy: 0.802. Test loss: 0.508. Test Accuracy: 0.754\n",
      "Epoch [31/40]. Train Loss: 0.442. Train Accuracy: 0.804. Test loss: 0.485. Test Accuracy: 0.764\n",
      "Epoch [32/40]. Train Loss: 0.441. Train Accuracy: 0.804. Test loss: 0.481. Test Accuracy: 0.765\n",
      "Epoch [33/40]. Train Loss: 0.440. Train Accuracy: 0.805. Test loss: 0.489. Test Accuracy: 0.761\n",
      "Epoch [34/40]. Train Loss: 0.440. Train Accuracy: 0.805. Test loss: 0.492. Test Accuracy: 0.763\n",
      "Epoch [35/40]. Train Loss: 0.438. Train Accuracy: 0.805. Test loss: 0.479. Test Accuracy: 0.768\n",
      "Epoch [36/40]. Train Loss: 0.438. Train Accuracy: 0.807. Test loss: 0.482. Test Accuracy: 0.767\n",
      "Epoch [37/40]. Train Loss: 0.437. Train Accuracy: 0.808. Test loss: 0.478. Test Accuracy: 0.768\n",
      "Epoch [38/40]. Train Loss: 0.437. Train Accuracy: 0.807. Test loss: 0.477. Test Accuracy: 0.767\n",
      "Epoch [39/40]. Train Loss: 0.436. Train Accuracy: 0.808. Test loss: 0.484. Test Accuracy: 0.767\n",
      "Epoch [40/40]. Train Loss: 0.435. Train Accuracy: 0.808. Test loss: 0.486. Test Accuracy: 0.767\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "conv_model = ConvNet(embed_dim=128, conv_filters=128, kernel_size=5, conv_stride=1)\n",
    "train_nn(conv_model, epochs=40, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6624dc-1efc-4144-b0ef-aad98a12c067",
   "metadata": {},
   "source": [
    "В целом, свёрточная модель показала точность чуть ниже 77%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaa8018-8336-4575-af0c-f54fb2f2364b",
   "metadata": {},
   "source": [
    "### 2. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebae6681-8251-465c-b3c0-25b719f46e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnNet(nn.Module):\n",
    "    def __init__(self, embed_dim=128, hidden_dim=128):\n",
    "        torch.random.manual_seed(RANDOM_STATE)\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, embed_dim, padding_idx=0)\n",
    "        \n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Sequential(nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                                 nn.ReLU())\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim // 2, 1)\n",
    "        self.dp02 = nn.Dropout(0.2)\n",
    "        self.dp05 = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dp02(x)\n",
    "        \n",
    "        # Берём только вектор последнего скрытого состояния,  \n",
    "        # он выполнит роль своеобразного пулинга перед полносвязной сетью\n",
    "        _, x = self.gru(x) \n",
    "        \n",
    "        x = self.fc1(torch.squeeze(x))\n",
    "        x = self.dp05(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a7c070e-bd0d-49fe-a14c-2159b5f266a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "RnnNet                                   --\n",
       "├─Embedding: 1-1                         40,704\n",
       "├─GRU: 1-2                               99,072\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Linear: 2-1                       8,256\n",
       "│    └─ReLU: 2-2                         --\n",
       "├─Linear: 1-4                            65\n",
       "├─Dropout: 1-5                           --\n",
       "├─Dropout: 1-6                           --\n",
       "=================================================================\n",
       "Total params: 148,097\n",
       "Trainable params: 148,097\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(RnnNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b020300-eb4d-498e-8a2d-48f4f9e4a1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40]. Train Loss: 0.693. Train Accuracy: 0.506. Test loss: 0.693. Test Accuracy: 0.504\n",
      "Epoch [2/40]. Train Loss: 0.693. Train Accuracy: 0.507. Test loss: 0.693. Test Accuracy: 0.505\n",
      "Epoch [3/40]. Train Loss: 0.693. Train Accuracy: 0.508. Test loss: 0.693. Test Accuracy: 0.505\n",
      "Epoch [4/40]. Train Loss: 0.693. Train Accuracy: 0.509. Test loss: 0.693. Test Accuracy: 0.508\n",
      "Epoch [5/40]. Train Loss: 0.693. Train Accuracy: 0.511. Test loss: 0.693. Test Accuracy: 0.508\n",
      "Epoch [6/40]. Train Loss: 0.616. Train Accuracy: 0.644. Test loss: 0.552. Test Accuracy: 0.704\n",
      "Epoch [7/40]. Train Loss: 0.541. Train Accuracy: 0.723. Test loss: 0.523. Test Accuracy: 0.726\n",
      "Epoch [8/40]. Train Loss: 0.520. Train Accuracy: 0.738. Test loss: 0.511. Test Accuracy: 0.733\n",
      "Epoch [9/40]. Train Loss: 0.508. Train Accuracy: 0.746. Test loss: 0.500. Test Accuracy: 0.742\n",
      "Epoch [10/40]. Train Loss: 0.499. Train Accuracy: 0.754. Test loss: 0.510. Test Accuracy: 0.736\n",
      "Epoch [11/40]. Train Loss: 0.490. Train Accuracy: 0.759. Test loss: 0.490. Test Accuracy: 0.750\n",
      "Epoch [12/40]. Train Loss: 0.484. Train Accuracy: 0.764. Test loss: 0.488. Test Accuracy: 0.754\n",
      "Epoch [13/40]. Train Loss: 0.478. Train Accuracy: 0.769. Test loss: 0.493. Test Accuracy: 0.752\n",
      "Epoch [14/40]. Train Loss: 0.473. Train Accuracy: 0.772. Test loss: 0.480. Test Accuracy: 0.758\n",
      "Epoch [15/40]. Train Loss: 0.468. Train Accuracy: 0.776. Test loss: 0.490. Test Accuracy: 0.749\n",
      "Epoch [16/40]. Train Loss: 0.463. Train Accuracy: 0.779. Test loss: 0.476. Test Accuracy: 0.763\n",
      "Epoch [17/40]. Train Loss: 0.458. Train Accuracy: 0.783. Test loss: 0.473. Test Accuracy: 0.762\n",
      "Epoch [18/40]. Train Loss: 0.456. Train Accuracy: 0.785. Test loss: 0.476. Test Accuracy: 0.761\n",
      "Epoch [19/40]. Train Loss: 0.451. Train Accuracy: 0.788. Test loss: 0.474. Test Accuracy: 0.766\n",
      "Epoch [20/40]. Train Loss: 0.448. Train Accuracy: 0.791. Test loss: 0.468. Test Accuracy: 0.768\n",
      "Epoch [21/40]. Train Loss: 0.444. Train Accuracy: 0.794. Test loss: 0.469. Test Accuracy: 0.768\n",
      "Epoch [22/40]. Train Loss: 0.441. Train Accuracy: 0.797. Test loss: 0.466. Test Accuracy: 0.767\n",
      "Epoch [23/40]. Train Loss: 0.436. Train Accuracy: 0.799. Test loss: 0.464. Test Accuracy: 0.770\n",
      "Epoch [24/40]. Train Loss: 0.435. Train Accuracy: 0.801. Test loss: 0.473. Test Accuracy: 0.769\n",
      "Epoch [25/40]. Train Loss: 0.433. Train Accuracy: 0.802. Test loss: 0.469. Test Accuracy: 0.770\n",
      "Epoch [26/40]. Train Loss: 0.429. Train Accuracy: 0.804. Test loss: 0.464. Test Accuracy: 0.773\n",
      "Epoch [27/40]. Train Loss: 0.426. Train Accuracy: 0.806. Test loss: 0.468. Test Accuracy: 0.771\n",
      "Epoch [28/40]. Train Loss: 0.423. Train Accuracy: 0.808. Test loss: 0.467. Test Accuracy: 0.772\n",
      "Epoch [29/40]. Train Loss: 0.421. Train Accuracy: 0.810. Test loss: 0.463. Test Accuracy: 0.773\n",
      "Epoch [30/40]. Train Loss: 0.418. Train Accuracy: 0.812. Test loss: 0.472. Test Accuracy: 0.771\n",
      "Epoch [31/40]. Train Loss: 0.415. Train Accuracy: 0.813. Test loss: 0.472. Test Accuracy: 0.771\n",
      "Epoch [32/40]. Train Loss: 0.413. Train Accuracy: 0.815. Test loss: 0.461. Test Accuracy: 0.775\n",
      "Epoch [33/40]. Train Loss: 0.411. Train Accuracy: 0.816. Test loss: 0.461. Test Accuracy: 0.777\n",
      "Epoch [34/40]. Train Loss: 0.408. Train Accuracy: 0.818. Test loss: 0.463. Test Accuracy: 0.775\n",
      "Epoch [35/40]. Train Loss: 0.406. Train Accuracy: 0.819. Test loss: 0.465. Test Accuracy: 0.777\n",
      "Epoch [36/40]. Train Loss: 0.403. Train Accuracy: 0.822. Test loss: 0.466. Test Accuracy: 0.777\n",
      "Epoch [37/40]. Train Loss: 0.402. Train Accuracy: 0.822. Test loss: 0.470. Test Accuracy: 0.774\n",
      "Epoch [38/40]. Train Loss: 0.401. Train Accuracy: 0.823. Test loss: 0.460. Test Accuracy: 0.779\n",
      "Epoch [39/40]. Train Loss: 0.398. Train Accuracy: 0.825. Test loss: 0.470. Test Accuracy: 0.777\n",
      "Epoch [40/40]. Train Loss: 0.396. Train Accuracy: 0.828. Test loss: 0.469. Test Accuracy: 0.778\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "rnn_model = RnnNet(embed_dim=128, hidden_dim=128)\n",
    "train_nn(rnn_model, epochs=40, lr=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39617298-d88e-4cbd-bff3-421c120c7e79",
   "metadata": {},
   "source": [
    "Точность рекуррентной модели чуть ниже 78%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c824e9-9bee-4fde-a409-57408d7e3bd4",
   "metadata": {},
   "source": [
    "### 3. CNN -> RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f2e9fa-e56d-4748-9a9e-710990a9caa6",
   "metadata": {},
   "source": [
    "Здесь, в отличие от просто CNN сети, мы не будем использовать пулинг после свёртки, так как нам нужно всё получившееся пространство, которое будет эмбеддингом для рекуррентной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64df5974-8abd-4f8b-b4ad-fd8d15f59873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRnnNet(nn.Module):\n",
    "    def __init__(self, embed_dim=128, hidden_dim=128, conv_filters=128, kernel_size=3, conv_stride=1):\n",
    "        torch.random.manual_seed(RANDOM_STATE)\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, embed_dim, padding_idx=0)\n",
    "        \n",
    "        self.conv = nn.Sequential(nn.Conv1d(embed_dim, conv_filters, kernel_size=kernel_size, stride=conv_stride),\n",
    "                                  nn.ReLU())\n",
    "        \n",
    "        self.gru = nn.GRU(conv_filters, hidden_dim, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Sequential(nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                                 nn.ReLU())\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim // 2, 1)\n",
    "        self.dp02 = nn.Dropout(0.2)\n",
    "        self.dp05 = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dp02(x)\n",
    "        x = x.permute(0, 2 ,1)\n",
    "        x = self.conv(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        _, x = self.gru(x)\n",
    "        x = self.fc1(torch.squeeze(x))\n",
    "        x = self.dp05(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d812c29-615a-4c82-87b9-96a727b631c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ConvRnnNet                               --\n",
       "├─Embedding: 1-1                         40,704\n",
       "├─Sequential: 1-2                        --\n",
       "│    └─Conv1d: 2-1                       49,280\n",
       "│    └─ReLU: 2-2                         --\n",
       "├─GRU: 1-3                               99,072\n",
       "├─Sequential: 1-4                        --\n",
       "│    └─Linear: 2-3                       8,256\n",
       "│    └─ReLU: 2-4                         --\n",
       "├─Linear: 1-5                            65\n",
       "├─Dropout: 1-6                           --\n",
       "├─Dropout: 1-7                           --\n",
       "=================================================================\n",
       "Total params: 197,377\n",
       "Trainable params: 197,377\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(ConvRnnNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d66bf00-fdee-4726-977e-ec743b84f93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]. Train Loss: 0.693. Train Accuracy: 0.507. Test loss: 0.693. Test Accuracy: 0.508\n",
      "Epoch [2/30]. Train Loss: 0.693. Train Accuracy: 0.510. Test loss: 0.693. Test Accuracy: 0.509\n",
      "Epoch [3/30]. Train Loss: 0.666. Train Accuracy: 0.538. Test loss: 0.660. Test Accuracy: 0.544\n",
      "Epoch [4/30]. Train Loss: 0.659. Train Accuracy: 0.547. Test loss: 0.619. Test Accuracy: 0.642\n",
      "Epoch [5/30]. Train Loss: 0.583. Train Accuracy: 0.682. Test loss: 0.538. Test Accuracy: 0.716\n",
      "Epoch [6/30]. Train Loss: 0.520. Train Accuracy: 0.740. Test loss: 0.503. Test Accuracy: 0.744\n",
      "Epoch [7/30]. Train Loss: 0.491. Train Accuracy: 0.762. Test loss: 0.479. Test Accuracy: 0.761\n",
      "Epoch [8/30]. Train Loss: 0.474. Train Accuracy: 0.775. Test loss: 0.473. Test Accuracy: 0.768\n",
      "Epoch [9/30]. Train Loss: 0.461. Train Accuracy: 0.784. Test loss: 0.462. Test Accuracy: 0.772\n",
      "Epoch [10/30]. Train Loss: 0.451. Train Accuracy: 0.792. Test loss: 0.458. Test Accuracy: 0.776\n",
      "Epoch [11/30]. Train Loss: 0.442. Train Accuracy: 0.797. Test loss: 0.451. Test Accuracy: 0.779\n",
      "Epoch [12/30]. Train Loss: 0.436. Train Accuracy: 0.801. Test loss: 0.455. Test Accuracy: 0.779\n",
      "Epoch [13/30]. Train Loss: 0.429. Train Accuracy: 0.806. Test loss: 0.455. Test Accuracy: 0.778\n",
      "Epoch [14/30]. Train Loss: 0.423. Train Accuracy: 0.810. Test loss: 0.449. Test Accuracy: 0.783\n",
      "Epoch [15/30]. Train Loss: 0.418. Train Accuracy: 0.813. Test loss: 0.461. Test Accuracy: 0.773\n",
      "Epoch [16/30]. Train Loss: 0.413. Train Accuracy: 0.817. Test loss: 0.452. Test Accuracy: 0.780\n",
      "Epoch [17/30]. Train Loss: 0.408. Train Accuracy: 0.822. Test loss: 0.445. Test Accuracy: 0.787\n",
      "Epoch [18/30]. Train Loss: 0.405. Train Accuracy: 0.824. Test loss: 0.447. Test Accuracy: 0.787\n",
      "Epoch [19/30]. Train Loss: 0.400. Train Accuracy: 0.827. Test loss: 0.445. Test Accuracy: 0.787\n",
      "Epoch [20/30]. Train Loss: 0.395. Train Accuracy: 0.830. Test loss: 0.444. Test Accuracy: 0.788\n",
      "Epoch [21/30]. Train Loss: 0.391. Train Accuracy: 0.834. Test loss: 0.447. Test Accuracy: 0.790\n",
      "Epoch [22/30]. Train Loss: 0.387. Train Accuracy: 0.836. Test loss: 0.447. Test Accuracy: 0.788\n",
      "Epoch [23/30]. Train Loss: 0.384. Train Accuracy: 0.839. Test loss: 0.448. Test Accuracy: 0.785\n",
      "Epoch [24/30]. Train Loss: 0.381. Train Accuracy: 0.842. Test loss: 0.449. Test Accuracy: 0.788\n",
      "Epoch [25/30]. Train Loss: 0.377. Train Accuracy: 0.844. Test loss: 0.450. Test Accuracy: 0.788\n",
      "Epoch [26/30]. Train Loss: 0.373. Train Accuracy: 0.847. Test loss: 0.458. Test Accuracy: 0.787\n",
      "Epoch [27/30]. Train Loss: 0.369. Train Accuracy: 0.848. Test loss: 0.458. Test Accuracy: 0.791\n",
      "Epoch [28/30]. Train Loss: 0.367. Train Accuracy: 0.851. Test loss: 0.449. Test Accuracy: 0.789\n",
      "Epoch [29/30]. Train Loss: 0.364. Train Accuracy: 0.853. Test loss: 0.451. Test Accuracy: 0.792\n",
      "Epoch [30/30]. Train Loss: 0.360. Train Accuracy: 0.856. Test loss: 0.462. Test Accuracy: 0.789\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "conv_rnn_model = ConvRnnNet(kernel_size=5)\n",
    "train_nn(conv_rnn_model, epochs=30, lr=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c89e23-b103-47ef-b0c8-bdf722a819c3",
   "metadata": {},
   "source": [
    "Данная связка показала точность 79%. Эта модель обошла наш бейзлайн."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa53c052-780f-4425-9666-8df5f6864cd7",
   "metadata": {},
   "source": [
    "### 4. RNN -> CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2155ad2c-14fc-424c-9cd8-7bd12a32987d",
   "metadata": {},
   "source": [
    "Здесь уже выходы рекуррентной сети будут эмбеддингами свёрточной сети. Поэтому из рекуррентной сети берём не только вектор последнего скрытого состояния, а все вектора скрытого состояния, на каждом временном отрезке t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0cc2e4e9-2c85-4365-b5b4-0b83840e7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnConvNet(nn.Module):\n",
    "    def __init__(self, embed_dim=128, hidden_dim=128, conv_filters=128, kernel_size=3, conv_stride=1):\n",
    "        torch.random.manual_seed(RANDOM_STATE)\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, embed_dim, padding_idx=0)\n",
    "        \n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        self.conv = nn.Sequential(nn.Conv1d(hidden_dim, conv_filters, kernel_size=kernel_size, stride=conv_stride),\n",
    "                                  nn.MaxPool1d(MAX_LEN // conv_stride - kernel_size + 1),\n",
    "                                  nn.ReLU())\n",
    "        \n",
    "        self.fc1 = nn.Sequential(nn.Linear(conv_filters, conv_filters // 2),\n",
    "                                 nn.ReLU())\n",
    "        \n",
    "        self.dp02 = nn.Dropout(0.2)\n",
    "        self.dp05 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(conv_filters // 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dp02(x)\n",
    "        \n",
    "        # Берём все векторы h\n",
    "        x, _ = self.gru(x)\n",
    "        \n",
    "        x = x.permute(0, 2 ,1)\n",
    "        x = torch.squeeze(self.conv(x))\n",
    "        x = self.fc1(x)\n",
    "        x = self.dp05(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da757f50-3cd2-401b-ac27-635d85f63dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "RnnConvNet                               --\n",
       "├─Embedding: 1-1                         40,704\n",
       "├─GRU: 1-2                               99,072\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Conv1d: 2-1                       49,280\n",
       "│    └─MaxPool1d: 2-2                    --\n",
       "│    └─ReLU: 2-3                         --\n",
       "├─Sequential: 1-4                        --\n",
       "│    └─Linear: 2-4                       8,256\n",
       "│    └─ReLU: 2-5                         --\n",
       "├─Dropout: 1-5                           --\n",
       "├─Dropout: 1-6                           --\n",
       "├─Linear: 1-7                            65\n",
       "=================================================================\n",
       "Total params: 197,377\n",
       "Trainable params: 197,377\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(RnnConvNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a659364e-cbd6-45b1-9adb-f331fb351503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15]. Train Loss: 0.579. Train Accuracy: 0.693. Test loss: 0.532. Test Accuracy: 0.722\n",
      "Epoch [2/15]. Train Loss: 0.519. Train Accuracy: 0.743. Test loss: 0.514. Test Accuracy: 0.733\n",
      "Epoch [3/15]. Train Loss: 0.497. Train Accuracy: 0.761. Test loss: 0.493. Test Accuracy: 0.750\n",
      "Epoch [4/15]. Train Loss: 0.479. Train Accuracy: 0.774. Test loss: 0.487. Test Accuracy: 0.755\n",
      "Epoch [5/15]. Train Loss: 0.467. Train Accuracy: 0.782. Test loss: 0.476. Test Accuracy: 0.767\n",
      "Epoch [6/15]. Train Loss: 0.453. Train Accuracy: 0.790. Test loss: 0.479. Test Accuracy: 0.761\n",
      "Epoch [7/15]. Train Loss: 0.444. Train Accuracy: 0.797. Test loss: 0.470. Test Accuracy: 0.772\n",
      "Epoch [8/15]. Train Loss: 0.435. Train Accuracy: 0.803. Test loss: 0.462. Test Accuracy: 0.776\n",
      "Epoch [9/15]. Train Loss: 0.426. Train Accuracy: 0.809. Test loss: 0.458. Test Accuracy: 0.774\n",
      "Epoch [10/15]. Train Loss: 0.419. Train Accuracy: 0.814. Test loss: 0.458. Test Accuracy: 0.778\n",
      "Epoch [11/15]. Train Loss: 0.408. Train Accuracy: 0.821. Test loss: 0.459. Test Accuracy: 0.779\n",
      "Epoch [12/15]. Train Loss: 0.402. Train Accuracy: 0.826. Test loss: 0.459. Test Accuracy: 0.781\n",
      "Epoch [13/15]. Train Loss: 0.393. Train Accuracy: 0.830. Test loss: 0.471. Test Accuracy: 0.780\n",
      "Epoch [14/15]. Train Loss: 0.387. Train Accuracy: 0.834. Test loss: 0.469. Test Accuracy: 0.782\n",
      "Epoch [15/15]. Train Loss: 0.380. Train Accuracy: 0.839. Test loss: 0.465. Test Accuracy: 0.783\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "rnn_conv_model = RnnConvNet(kernel_size=5)\n",
    "train_nn(rnn_conv_model, epochs=15, lr=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a7672a-40f5-4d93-8db6-93e2f31484f8",
   "metadata": {},
   "source": [
    "Данная связка показала чуть более 78%. Она обогнала бейзлайн, который делал токенизацию по словам, но не превзошла бейзлайн с токенизацией по символам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ed10b-3688-480e-ad7e-70982959a006",
   "metadata": {},
   "source": [
    "<ins>Вывод:</ins>  \n",
    "Наименее результативной моделью оказалась свёрточная сеть, а связки моделей показали лучший результат. Лучшая связка CNN -> RNN даже обошла бейзлайн."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
